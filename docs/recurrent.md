# Recurrent architectures, fine-tuning and knowledge distillation

!!! danger

    This is work in progress. The contents of this page are not final and, therefore, it is not recommended to start working on its contents yet.

## Sesión del 21 de febrero de 2024

### Contenidos a preparar antes de la sesión del 21/02/2024

### Contenidos para la sesión presencial del 21/02/2024

## Recurrent architectures

### Recurrent neural networks

### Long short-term memory

### Other recurrent architectures

## Parameter-efficient fine-tuning

## Knowledge distillation

### Knowledge distillation for sequence-to-sequence models

#### Word-based knowledge distillation

#### Sentence-level knowledge distillation
